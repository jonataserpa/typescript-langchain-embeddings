# Sistema de Busca Sem√¢ntica com LangChain, Redis e PromptTemplate

Este projeto implementa um sistema completo de busca sem√¢ntica usando LangChain, OpenAI Embeddings, Redis Vector Store e PromptTemplate para respostas contextualizadas. O sistema processa PDFs, converte em chunks, cria embeddings e permite busca sem√¢ntica inteligente com respostas geradas por IA.

## üöÄ Funcionalidades

- **Processamento de PDF**: Extra√ß√£o de texto e divis√£o em chunks otimizados
- **LangChain Pipeline**: Load ‚Üí Transform ‚Üí Embed ‚Üí Store ‚Üí Retrieve
- **OpenAI Embeddings**: Cria√ß√£o de representa√ß√µes sem√¢nticas usando GPT
- **Redis Vector Store**: Armazenamento e busca vetorial de alta performance
- **PromptTemplate**: Respostas contextualizadas com LLM
- **API REST**: Endpoints para busca sem√¢ntica e perguntas
- **Processamento em Lotes**: Otimizado para grandes volumes de dados
- **RedisInsight**: Interface visual para visualizar dados no Redis

## üìã Pr√©-requisitos

- Node.js 18+
- Docker e Docker Compose
- Chave API do OpenAI
- Redis Stack (via Docker)

## üõ†Ô∏è Instala√ß√£o

1. **Clone e instale depend√™ncias:**
```bash
cd /home/jonata/Documentos/typescript-langchain
npm install
```

2. **Configure as vari√°veis de ambiente:**
```bash
cp env.example .env
# Edite o arquivo .env com suas configura√ß√µes
```

3. **Configure sua chave OpenAI:**
```bash
# No arquivo .env
OPENAI_API_KEY=sua_chave_openai_aqui
```

4. **Inicie o Redis Stack:**
```bash
docker-compose up -d
```

## üìÅ Estrutura do Projeto

```
typescript-langchain/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ config/                    # Configura√ß√µes do sistema
‚îÇ   ‚îú‚îÄ‚îÄ services/                  # Servi√ßos principais
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ embeddingService.ts    # Cria√ß√£o de embeddings com OpenAI
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ langchainService.ts    # Servi√ßos do LangChain
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ promptService.ts       # PromptTemplate com LLM
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ redisVectorStore.ts    # Armazenamento no Redis
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ semanticSearchService.ts # Busca sem√¢ntica
‚îÇ   ‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pdfProcessor.ts        # Processamento de PDF
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ server.ts              # API REST
‚îÇ   ‚îú‚îÄ‚îÄ index.ts                   # Pipeline completo
‚îÇ   ‚îú‚îÄ‚îÄ processPdf.ts              # Processamento de PDF
‚îÇ   ‚îú‚îÄ‚îÄ process-all-chunks.ts      # Processamento completo otimizado
‚îÇ   ‚îú‚îÄ‚îÄ process-optimized.ts       # Processamento otimizado
‚îÇ   ‚îú‚îÄ‚îÄ test-pipeline.ts           # Teste do pipeline
‚îÇ   ‚îî‚îÄ‚îÄ search.ts                  # Interface de busca interativa
‚îú‚îÄ‚îÄ tmp/                           # PDFs para processar
‚îú‚îÄ‚îÄ chunks/                        # Chunks gerados (criado automaticamente)
‚îú‚îÄ‚îÄ docker-compose.yml             # Redis Stack + RedisInsight
‚îî‚îÄ‚îÄ package.json
```

## üéØ Ordem Exata de Execu√ß√£o

### 1. **Prepara√ß√£o do Ambiente**

```bash
# 1. Instalar depend√™ncias
npm install

# 2. Configurar vari√°veis de ambiente
cp env.example .env
# Editar .env com OPENAI_API_KEY

# 3. Iniciar Redis Stack
docker-compose up -d
```

### 2. **Processamento do PDF**

```bash
# Op√ß√£o A: Processamento completo (recomendado)
npm run process-all

# Op√ß√£o B: Processamento otimizado (para testes)
npm run process-optimized -- --max=100 --batch=10

# Op√ß√£o C: Processamento b√°sico
npm run process-pdf
```

### 3. **Iniciar API REST**

```bash
# Iniciar servidor da API
npm run api

# A API estar√° dispon√≠vel em http://localhost:3000
```

### 4. **Fazer Perguntas**

```bash
# Via API REST
curl -X POST http://localhost:3000/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "Como funciona o hoisting em JavaScript?", "maxResults": 3}'

# Via interface interativa
npm run search
```

## üîß Scripts Dispon√≠veis

```bash
# Processamento
npm run process-pdf        # Processar apenas PDF em chunks
npm run process-all        # Processar todos os chunks (10.000+)
npm run process-optimized  # Processamento otimizado com par√¢metros
npm run test-pipeline      # Testar pipeline com 1 documento

# API e Busca
npm run api                # Iniciar API REST
npm run search             # Interface de busca interativa

# Desenvolvimento
npm run build              # Compilar TypeScript
npm run start              # Executar vers√£o compilada
npm run clean              # Limpar arquivos compilados
```

## üìä Pipeline Detalhado

### **Etapa 1: Processamento do PDF**
- **Ferramenta**: `PDFProcessor` (src/utils/pdfProcessor.ts)
- **Entrada**: PDF em `/tmp/JavaScript The Definitive Guide (David Flanagan).pdf`
- **Processo**: 
  - Extra√ß√£o de texto usando `pdf-parse`
  - Divis√£o em chunks de 600 caracteres com overlap de 100
  - Cria√ß√£o de metadados (p√°gina, chunk, fonte)
- **Sa√≠da**: Arquivos JSON em `/chunks/` (10.000+ chunks)

### **Etapa 2: Cria√ß√£o de Embeddings**
- **Ferramenta**: `EmbeddingService` (src/services/embeddingService.ts)
- **Modelo**: `text-embedding-ada-002` (OpenAI)
- **Processo**:
  - Processamento em lotes de 50 documentos
  - Rate limiting e retry autom√°tico
  - Logs detalhados de progresso
- **Sa√≠da**: Vetores de 1536 dimens√µes para cada chunk

### **Etapa 3: Armazenamento no Redis**
- **Ferramenta**: `RedisVectorStoreService` (src/services/redisVectorStore.ts)
- **Banco**: Redis Stack (porta 6379)
- **√çndice**: `javascript_guide_vectors`
- **Chaves**: `js_guide:0`, `js_guide:1`, ..., `js_guide:9999`
- **Processo**:
  - Salvamento em lotes para otimiza√ß√£o
  - Verifica√ß√£o de integridade
  - Logs detalhados de cada opera√ß√£o

### **Etapa 4: Busca Sem√¢ntica**
- **Ferramenta**: `SemanticSearchService` (src/services/semanticSearchService.ts)
- **Processo**:
  - Convers√£o da pergunta em embedding
  - Busca por similaridade no Redis
  - Filtragem por score de relev√¢ncia
  - Retorno dos documentos mais relevantes

### **Etapa 5: Gera√ß√£o de Respostas**
- **Ferramenta**: `PromptService` (src/services/promptService.ts)
- **Modelo**: `gpt-3.5-turbo` (OpenAI)
- **Processo**:
  - Valida√ß√£o de contexto JavaScript
  - Constru√ß√£o de prompt com contexto
  - Gera√ß√£o de resposta contextualizada
  - Avalia√ß√£o de confian√ßa e relev√¢ncia

## üóÑÔ∏è Onde os Dados s√£o Salvos

### **Redis Stack**
- **Porta**: 6379
- **√çndice**: `javascript_guide_vectors`
- **Estrutura**:
  ```
  js_guide:0    -> {content: "texto do chunk", metadata: {...}, embedding: [...]}
  js_guide:1    -> {content: "texto do chunk", metadata: {...}, embedding: [...]}
  ...
  js_guide:9999 -> {content: "texto do chunk", metadata: {...}, embedding: [...]}
  ```

### **RedisInsight (Visualiza√ß√£o)**
- **URL**: http://localhost:8002
- **Funcionalidade**: Interface web para visualizar dados do Redis
- **Acesso**: Abrir no navegador ap√≥s `docker-compose up -d`

### **Arquivos Locais**
- **Chunks**: `/chunks/*.json` (10.000+ arquivos)
- **Logs**: Console com informa√ß√µes detalhadas

## üîç Como Fazer Perguntas

### **Via API REST**

```bash
# Pergunta simples
curl -X POST http://localhost:3000/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "O que √© JavaScript?", "maxResults": 3}'

# Pergunta com par√¢metros
curl -X POST http://localhost:3000/ask \
  -H "Content-Type: application/json" \
  -d '{
    "question": "Como funciona o hoisting em JavaScript?",
    "maxResults": 5,
    "scoreThreshold": 0.8
  }'

# Resposta contextualizada
curl -X POST http://localhost:3000/answer \
  -H "Content-Type: application/json" \
  -d '{"question": "Explique closures em JavaScript"}'
```

### **Via Interface Interativa**

```bash
npm run search
# Digite sua pergunta quando solicitado
```

### **Exemplos de Perguntas V√°lidas**

- "O que √© JavaScript e para que serve?"
- "Como funciona o hoisting em JavaScript?"
- "Explique closures em JavaScript"
- "Como manipular o DOM com JavaScript?"
- "O que s√£o promises em JavaScript?"
- "Como funciona o sistema de heran√ßa em JavaScript?"
- "Explique async/await em JavaScript"

## üìä Endpoints da API

### **GET /health**
- Verifica status do sistema
- Retorna: conex√£o Redis, OpenAI, documentos indexados

### **GET /stats**
- Estat√≠sticas do sistema
- Retorna: n√∫mero de documentos, tamanho do √≠ndice

### **POST /search**
- Busca sem√¢ntica b√°sica
- Par√¢metros: `query`, `maxResults`, `scoreThreshold`

### **POST /ask**
- Pergunta com resposta contextualizada
- Par√¢metros: `question`, `maxResults`, `scoreThreshold`
- Retorna: resposta gerada por IA + fontes

### **POST /answer**
- Resposta contextualizada avan√ßada
- Par√¢metros: `question`, `maxResults`, `scoreThreshold`
- Retorna: resposta + metadados de confian√ßa

### **GET /api-docs**
- Documenta√ß√£o completa da API
- Lista todos os endpoints dispon√≠veis

## ‚öôÔ∏è Configura√ß√µes

### **Vari√°veis de Ambiente (.env)**

```bash
# OpenAI
OPENAI_API_KEY=sua_chave_aqui
EMBEDDING_MODEL=text-embedding-ada-002

# Redis
REDIS_URL=redis://localhost:6379
REDIS_PASSWORD=

# Chunks
CHUNK_SIZE=600
CHUNK_OVERLAP=100

# API
API_PORT=3000
```

### **Configura√ß√µes do Sistema**

```typescript
// src/config/config.ts
export const config = {
  openai: {
    apiKey: process.env.OPENAI_API_KEY,
    embeddingModel: 'text-embedding-ada-002',
    chatModel: 'gpt-3.5-turbo'
  },
  redis: {
    url: process.env.REDIS_URL || 'redis://localhost:6379',
    indexName: 'javascript_guide_vectors',
    keyPrefix: 'js_guide:'
  },
  chunks: {
    size: 600,
    overlap: 100
  }
};
```

## üè• Health Check

O sistema inclui verifica√ß√µes de sa√∫de para:
- ‚úÖ Conex√£o OpenAI Embeddings
- ‚úÖ Conex√£o Redis
- ‚úÖ Vector Store funcionando
- ‚úÖ Documentos indexados (10.000+)
- ‚úÖ PromptService funcionando

## üìà Performance

- **Chunks**: 600 caracteres com overlap de 100
- **Batch Size**: 50 documentos por lote (embeddings)
- **Busca**: Top 5 resultados com threshold de 0.8
- **Redis**: Persist√™ncia autom√°tica configurada
- **Processamento**: ~10.000 chunks em ~5-10 minutos
- **Resposta**: < 2 segundos para perguntas

## üê≥ Docker

```bash
# Iniciar Redis Stack + RedisInsight
docker-compose up -d

# Ver logs
docker-compose logs -f

# Parar
docker-compose down

# Verificar status
docker-compose ps
```

## üîß Troubleshooting

### **Erro de Conex√£o OpenAI**
- Verifique se `OPENAI_API_KEY` est√° configurada
- Confirme se tem cr√©ditos dispon√≠veis na conta
- Teste: `npm run test-pipeline`

### **Erro de Conex√£o Redis**
- Verifique se Docker est√° rodando
- Confirme se Redis Stack est√° ativo: `docker-compose ps`
- Teste: `redis-cli ping`

### **PDF n√£o encontrado**
- Verifique se o PDF est√° em `/tmp/`
- Confirme o nome exato do arquivo
- Execute: `ls -la tmp/`

### **Chunks n√£o salvos**
- Verifique logs do processamento
- Confirme se Redis est√° funcionando
- Execute: `npm run process-all`

### **Resposta n√£o contextualizada**
- Verifique se PromptService est√° funcionando
- Confirme se h√° documentos no Redis
- Teste: `curl http://localhost:3000/health`

## üìù Logs Detalhados

O sistema gera logs detalhados para cada etapa:

```
üöÄ INICIANDO PROCESSAMENTO COMPLETO
üìÑ PDF encontrado: JavaScript The Definitive Guide (David Flanagan).pdf
üìä Total de chunks: 10000
üß† Criando embeddings para 10000 textos...
‚è≥ Processando lote 1/200 (50 documentos)...
‚úÖ Lote 1 processado e salvo no Redis
üíæ Documentos salvos no Redis: 50/10000
...
üéâ PROCESSAMENTO CONCLU√çDO: 10000 chunks salvos
```

## üéØ Pr√≥ximos Passos

- [x] Processamento completo de 10.000+ chunks
- [x] API REST com endpoints completos
- [x] PromptTemplate com respostas contextualizadas
- [x] RedisInsight para visualiza√ß√£o
- [x] Processamento em lotes otimizado
- [ ] Interface web para busca
- [ ] Suporte a m√∫ltiplos PDFs
- [ ] Cache de embeddings
- [ ] M√©tricas de performance avan√ßadas
- [ ] Filtros por metadados

## üìö Tecnologias Utilizadas

- **LangChain**: Pipeline de processamento de documentos
- **OpenAI**: Embeddings (text-embedding-ada-002) e Chat (gpt-3.5-turbo)
- **Redis Stack**: Vector Store para busca sem√¢ntica
- **RedisInsight**: Interface visual para Redis
- **TypeScript**: Desenvolvimento type-safe
- **Express.js**: API REST
- **Docker**: Containeriza√ß√£o do Redis
- **pdf-parse**: Processamento de PDFs